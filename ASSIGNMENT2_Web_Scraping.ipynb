{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b349423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pc\\anaconda3\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pc\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe212cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820abe03",
   "metadata": {},
   "source": [
    "Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7102272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launching the chrome browser\n",
    "\n",
    "driver=webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580e5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website to scrap\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e13d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac8e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a9692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')\n",
    "for x in title_tags[0:10]:\n",
    "    titles=x.text\n",
    "    job_title.append(titles)\n",
    "\n",
    "#scraping job location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"locWdth\"]')\n",
    "for x in location_tags[0:10]:\n",
    "    locations=x.text\n",
    "    job_location.append(locations)\n",
    "    \n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\" row2\"]/span/a[1]')\n",
    "for x in title_tags[0:10]:\n",
    "    companys=x.text\n",
    "    company_name.append(companys)\n",
    "    \n",
    "\n",
    "#scraping experience required from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')\n",
    "for x in title_tags[0:10]:\n",
    "    exp=x.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94eff25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff347a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist, Reporting</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Senior Data Scientist, Reporting</td>\n",
       "      <td>6-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist(python) Immediate joiner - Remote</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Scientist(python) Immediate joiner - Remote</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist-Senior Associate - P&amp;T Labs</td>\n",
       "      <td>Mumbai, Hyderabad, Bengaluru</td>\n",
       "      <td>Data Scientist-Senior Associate - P&amp;T Labs</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Architect</td>\n",
       "      <td>Temp. WFH - Hyderabad, Bengaluru</td>\n",
       "      <td>Data Scientist Architect</td>\n",
       "      <td>11-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Analyst- Clinical Data Management Scien...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Senior Analyst- Clinical Data Management Scien...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCL Hiring||Senior Data Scientist Role||Locati...</td>\n",
       "      <td>Hybrid - Pune, Maharashtra, Bangalore Rural, K...</td>\n",
       "      <td>HCL Hiring||Senior Data Scientist Role||Locati...</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DS - NLP Expert</td>\n",
       "      <td>Hyderabad, Telangana, Gurugram, Haryana, Banga...</td>\n",
       "      <td>DS - NLP Expert</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad, Chennai, Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                   Senior Data Scientist, Reporting   \n",
       "1                                     Data Scientist   \n",
       "2   Data Scientist(python) Immediate joiner - Remote   \n",
       "3         Data Scientist-Senior Associate - P&T Labs   \n",
       "4                           Data Scientist Architect   \n",
       "5  Senior Analyst- Clinical Data Management Scien...   \n",
       "6                                     Data Scientist   \n",
       "7  HCL Hiring||Senior Data Scientist Role||Locati...   \n",
       "8                                    DS - NLP Expert   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "2                                             Remote   \n",
       "3                       Mumbai, Hyderabad, Bengaluru   \n",
       "4                   Temp. WFH - Hyderabad, Bengaluru   \n",
       "5                                          Bengaluru   \n",
       "6                                          Bengaluru   \n",
       "7  Hybrid - Pune, Maharashtra, Bangalore Rural, K...   \n",
       "8  Hyderabad, Telangana, Gurugram, Haryana, Banga...   \n",
       "9                      Hyderabad, Chennai, Bengaluru   \n",
       "\n",
       "                                        Company Name Experience  \n",
       "0                   Senior Data Scientist, Reporting    6-7 Yrs  \n",
       "1                                     Data Scientist    3-6 Yrs  \n",
       "2   Data Scientist(python) Immediate joiner - Remote    2-7 Yrs  \n",
       "3         Data Scientist-Senior Associate - P&T Labs    4-6 Yrs  \n",
       "4                           Data Scientist Architect  11-20 Yrs  \n",
       "5  Senior Analyst- Clinical Data Management Scien...    5-8 Yrs  \n",
       "6                                     Data Scientist    3-5 Yrs  \n",
       "7  HCL Hiring||Senior Data Scientist Role||Locati...  10-20 Yrs  \n",
       "8                                    DS - NLP Expert   6-11 Yrs  \n",
       "9                                     Data Scientist   5-10 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':job_title, 'Location':job_location, 'Company Name':company_name, 'Experience':experience_required})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92a778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30222ba8",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2eccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launching the chrome browser\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c89d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website to scrap\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "163150a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a47e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c87a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title1=[]\n",
    "job_location1=[]\n",
    "company_name1=[]\n",
    "experience_required1=[]\n",
    "\n",
    "#scraping job title from given page\n",
    "title_tags1=driver.find_elements(By.XPATH,'//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]/a')\n",
    "for x in title_tags1[0:10]:\n",
    "    titles1=x.text\n",
    "    job_title1.append(titles1)\n",
    "\n",
    "#scraping job location from given page\n",
    "location_tags1=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for x in location_tags1[0:10]:\n",
    "    locations1=x.text\n",
    "    job_location1.append(locations1)\n",
    "    \n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags1=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for x in title_tags1[0:10]:\n",
    "    companys1=x.text\n",
    "    company_name1.append(companys1)\n",
    "    \n",
    "\n",
    "#scraping experience required from given page\n",
    "exp_require1=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for x in exp_require1[0:10]:\n",
    "    exp=x.text\n",
    "    experience_required1.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "374f8fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title1),len(job_location1),len(company_name1),len(experience_required1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284657e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (Power BI, Python, SQL)- Internal...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Data Analyst (Power BI, Python, SQL)- Internal...</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>9 to 14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>12 to 22 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Governance Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Data Governance Analyst</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>12 to 22 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer Ii</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>Data Engineer Ii</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "1                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "2  Data Analyst (Power BI, Python, SQL)- Internal...       Bangalore   \n",
       "3                                       Data Analyst  Bangalore\\n+12   \n",
       "4                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "5                                       Data Analyst   Bangalore\\n+9   \n",
       "6                            Data Governance Analyst       Bangalore   \n",
       "7                                       Data Analyst   Bangalore\\n+9   \n",
       "8                                   Data Engineer Ii   Bangalore\\n+9   \n",
       "9                            Hiring For Data Analyst  Bangalore\\n+12   \n",
       "\n",
       "                                        Company Name    Experience  \n",
       "0                           Data Analyst Recruitment    0 to 4 Yrs  \n",
       "1                           Data Analyst Recruitment    0 to 4 Yrs  \n",
       "2  Data Analyst (Power BI, Python, SQL)- Internal...    3 to 8 Yrs  \n",
       "3                                       Data Analyst   9 to 14 Yrs  \n",
       "4                              Clinical Data Analyst     0 to 1 Yr  \n",
       "5                                       Data Analyst  12 to 22 Yrs  \n",
       "6                            Data Governance Analyst    5 to 8 Yrs  \n",
       "7                                       Data Analyst  12 to 22 Yrs  \n",
       "8                                   Data Engineer Ii     0 to 1 Yr  \n",
       "9                            Hiring For Data Analyst    0 to 4 Yrs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame({'Title':job_title1, 'Location':job_location1, 'Company Name':company_name1, 'Experience':experience_required1})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a867a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37759e26",
   "metadata": {},
   "source": [
    "Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "            As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95ca432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbc6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launching the chrome browser\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6854ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website to scrap\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710fd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "#scraping rating from given page\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for x in rating_tags:\n",
    "        ratings=x.text\n",
    "        rating.append(ratings)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "#scraping review summary from given page\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    summary_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for x in summary_tags:\n",
    "        summarys=x.text\n",
    "        review_summary.append(summarys)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "#scraping full review from given page\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div/div')\n",
    "    for x in full_tags:\n",
    "        fulls=x.text\n",
    "        full_review.append(fulls)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220a2a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb991e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Terrific!!! Lucky to get this phone in first l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Just upgraded from 6s to 11. Yes its been a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>After 20 days above writing this review\\n\\nI a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Just the display held it from being a 5star ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Mind blowing purchase battery back up is excel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Best iphone budget wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Nice product... And happy with the facility gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Nice product very happy with the service of Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Very Good phone.. beautiful camera.. go for it❤️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5               Super!   \n",
       "1       5            Wonderful   \n",
       "2       5            Just wow!   \n",
       "3       5   Highly recommended   \n",
       "4       5   Highly recommended   \n",
       "..    ...                  ...   \n",
       "95      5            Must buy!   \n",
       "96      5    Terrific purchase   \n",
       "97      5   Highly recommended   \n",
       "98      5       Classy product   \n",
       "99      5  Best in the market!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Terrific!!! Lucky to get this phone in first l...  \n",
       "1   Just upgraded from 6s to 11. Yes its been a lo...  \n",
       "2   After 20 days above writing this review\\n\\nI a...  \n",
       "3   Just the display held it from being a 5star ph...  \n",
       "4   Mind blowing purchase battery back up is excel...  \n",
       "..                                                ...  \n",
       "95                            Best iphone budget wise  \n",
       "96  Nice product... And happy with the facility gi...  \n",
       "97  Nice product very happy with the service of Fl...  \n",
       "98                                               Good  \n",
       "99   Very Good phone.. beautiful camera.. go for it❤️  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame({'Rating':rating, 'Review Summary':review_summary, 'Full Review':full_review})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2cfe0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1180e0f",
   "metadata": {},
   "source": [
    "Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8831be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a8864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launching the chrome browser\n",
    "\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3c5657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website to scrap\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3beb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"Pke_EE \")\n",
    "designation.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd1a775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_2iLD__\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a478cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "\n",
    "#scraping brand from given page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for x in brand_tags[0:100]:\n",
    "        brands=x.text\n",
    "        brand.append(brands)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "#scraping product description from given page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    product_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]/a[1]')\n",
    "    for x in product_tags[0:100]:\n",
    "        products=x.text\n",
    "        product_description.append(products)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "#scraping price from given page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for x in price_tags[0:100]:\n",
    "        prices=x.text\n",
    "        price.append(prices)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebc85fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152c8245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Footox</td>\n",
       "      <td>GRAND COURT 2.0 Sneakers For Women</td>\n",
       "      <td>₹655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-ROCK</td>\n",
       "      <td>SUMMITS Sneakers For Men</td>\n",
       "      <td>₹2,087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Seattle Sneakers For Men</td>\n",
       "      <td>₹1,709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>PC Runner Sneakers For Men</td>\n",
       "      <td>₹1,066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>VENDOZ</td>\n",
       "      <td>Smash V2 L Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>SKECH-LITE PRO - CLE Sneakers For Men</td>\n",
       "      <td>₹1,139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>asian</td>\n",
       "      <td>Rebound Future EVO Core Sneakers For Men</td>\n",
       "      <td>₹11,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>Newton-01 Men's Lightweight Running Shoes Snea...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                Product Description    Price\n",
       "0      Footox                 GRAND COURT 2.0 Sneakers For Women     ₹655\n",
       "1      T-ROCK                           SUMMITS Sneakers For Men   ₹2,087\n",
       "2    RapidBox                           Seattle Sneakers For Men   ₹1,709\n",
       "3        PUMA                                   Sneakers For Men     ₹689\n",
       "4      BRUTON                         PC Runner Sneakers For Men   ₹1,066\n",
       "..        ...                                                ...      ...\n",
       "115    VENDOZ                        Smash V2 L Sneakers For Men     ₹449\n",
       "116    CAMPUS              SKECH-LITE PRO - CLE Sneakers For Men   ₹1,139\n",
       "117     asian           Rebound Future EVO Core Sneakers For Men  ₹11,699\n",
       "118    CAMPUS  Newton-01 Men's Lightweight Running Shoes Snea...     ₹399\n",
       "119      PUMA                                   Sneakers For Men     ₹295\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame({'Brand':brand, 'Product Description':product_description, 'Price':price})\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a1388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54155eb6",
   "metadata": {},
   "source": [
    "Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49338b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launching the chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d99df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website to scrap\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f602f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"nav-fill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eee3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_title=[]\n",
    "rating=[]\n",
    "price=[]\n",
    "\n",
    "#scraping job title from given page\n",
    "lapton_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for x in lapton_tags[0:10]:\n",
    "    laptops=x.text\n",
    "    laptop_title.append(laptops)\n",
    "\n",
    "#scraping rating from given page\n",
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span/span/a/i/span')\n",
    "for x in rating_tags[0:10]:\n",
    "    ratings=x.text\n",
    "    rating.append(ratings)\n",
    "    \n",
    "#scraping price from given page\n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price\"]')\n",
    "for x in price_tags[0:10]:\n",
    "    prices=x.text\n",
    "    price.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cec090e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(laptop_title),len(rating),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85dd2349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td></td>\n",
       "      <td>₹67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td></td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td></td>\n",
       "      <td>₹49,650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Yoga Slim7 Carbon Intel Evo i7 1260P 13...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,13,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 14th...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,49,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Victus Gaming Laptop, 12th Gen Intel Core i...</td>\n",
       "      <td></td>\n",
       "      <td>₹81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>₹76,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion X360 11th Gen Intel Core i7 14\" (3...</td>\n",
       "      <td></td>\n",
       "      <td>₹67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 11th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>₹59,500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title Rating      Price\n",
       "0  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...           ₹67,990\n",
       "1  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...           ₹59,990\n",
       "2  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...           ₹49,650\n",
       "3  Lenovo Yoga Slim7 Carbon Intel Evo i7 1260P 13...         ₹1,13,490\n",
       "4  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....           ₹59,990\n",
       "5  Acer Predator Helios Neo 16 Gaming Laptop 14th...         ₹1,49,999\n",
       "6  HP Victus Gaming Laptop, 12th Gen Intel Core i...           ₹81,990\n",
       "7  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...           ₹76,990\n",
       "8  HP Pavilion X360 11th Gen Intel Core i7 14\" (3...           ₹67,990\n",
       "9  Lenovo IdeaPad Slim 3 Intel Core i7 11th Gen 1...           ₹59,500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame({'Laptop Title':laptop_title, 'Rating':rating, 'Price':price})\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3aa647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e95180fb",
   "metadata": {},
   "source": [
    "Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on Top Quote\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ee9a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bde69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08ef4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote =[]\n",
    "author =[]\n",
    "type_quote=[]\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for x in quote_tags:\n",
    "    quotes=x.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "    \n",
    "author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]/a')\n",
    "for x in author_tags:\n",
    "    authors=x.text\n",
    "    author.append(authors)\n",
    "    \n",
    "    \n",
    "type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]/a[3]')\n",
    "for x in type_tags:\n",
    "    types=x.text\n",
    "    type_quote.append(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2bd6f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(quote),len(author),len(type_quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c73fef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quote                Author  \\\n",
       "0   The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1   One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2   Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3   Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4   You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                ...                   ...   \n",
       "95     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "96  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "97  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "98  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "99    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "        Type of Quote  \n",
       "0   Transcendentalism  \n",
       "1              Trying  \n",
       "2                 War  \n",
       "3               Death  \n",
       "4           Patriotic  \n",
       "..                ...  \n",
       "95            Hunting  \n",
       "96          Uplifting  \n",
       "97             Change  \n",
       "98             Mother  \n",
       "99             Change  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df6=pd.DataFrame({'Quote':quote,'Author':author, 'Type of Quote':type_quote})\n",
    "\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0daf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a25aac01",
   "metadata": {},
   "source": [
    "Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of\u0002all-prime-ministers-of-india-1473165149-1 scrap the mentioned data and make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "594b9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d3b7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.jagranjosh.com/general-knowledge/list-of\u0002all-prime-ministers-of-india-1473165149-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5589fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pres=[]\n",
    "born_date=[]\n",
    "term_office=[]\n",
    "remarks=[]\n",
    "\n",
    "#scraping name of president:\n",
    "\n",
    "name_tag=driver.find_element('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
